{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freealise/freealise/blob/main/opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcxH56uqg_tH",
        "outputId": "ba883cb6-a2f8-48c1-b294-76d773e7d3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (0.5.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "!pip install ffmpy\n",
        "import IPython.display as display\n",
        "from ffmpy import FFmpeg\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "img1 = cv.imread(\"cube_origs.jpg\", cv.IMREAD_UNCHANGED)\n",
        "img2 = cv.imread(\"cube_origs.jpg\", cv.IMREAD_UNCHANGED)\n",
        "img = np.concatenate((img1, img2), axis=1)\n",
        "cv.imwrite(\"cube.jpg\", img)\n",
        "\n",
        "ff = FFmpeg(\n",
        "    inputs={'cube.jpg': None },\n",
        "    outputs={'output.jpg': '-vf v360=dfisheye:equirect:ih_fov=180:iv_fov=180:yaw=90' }\n",
        ")\n",
        "ff.run()\n",
        "\n",
        "#video=\"output.jpg\"\n",
        "#display.display(display.Markdown(F\"\"\"![]({video})\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python mediapipe msvc-runtime\n",
        "# Import Libraries\n",
        "import cv2\n",
        "import time\n",
        "import mediapipe as mp\n",
        "\n",
        "# Grabbing the Holistic Model from Mediapipe and\n",
        "# Initializing the Model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic_model = mp_holistic.Holistic(\n",
        "  static_image_mode=True,\n",
        "  model_complexity=1,\n",
        "  smooth_landmarks=True,\n",
        "\tmin_detection_confidence=0.5,\n",
        "\tmin_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# Initializing the drawing utils for drawing the facial landmarks on image\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# (0) in VideoCapture is used to connect to your computer's default camera\n",
        "capture = cv2.VideoCapture(0)\n",
        "\n",
        "# Initializing current time and precious time for calculating the FPS\n",
        "previousTime = 0\n",
        "currentTime = 0\n",
        "\n",
        "while capture.isOpened():\n",
        "\t# capture frame by frame\n",
        "\tret, frame = capture.read()\n",
        "\n",
        "\t# resizing the frame for better view\n",
        "\tframe = cv2.resize(frame, (800, 600))\n",
        "\n",
        "\t# Converting the from BGR to RGB\n",
        "\timage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t# Making predictions using holistic model\n",
        "\t# To improve performance, optionally mark the image as not writeable to\n",
        "\t# pass by reference.\n",
        "\timage.flags.writeable = False\n",
        "\tresults = holistic_model.process(image)\n",
        "\timage.flags.writeable = True\n",
        "\n",
        "\t# Converting back the RGB image to BGR\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\t# Drawing the Facial Landmarks\n",
        "\tmp_drawing.draw_landmarks(\n",
        "\timage,\n",
        "\tresults.face_landmarks,\n",
        "\tmp_holistic.FACEMESH_CONTOURS,\n",
        "\tmp_drawing.DrawingSpec(\n",
        "\t\tcolor=(255,0,255),\n",
        "\t\tthickness=1,\n",
        "\t\tcircle_radius=1\n",
        "\t),\n",
        "\tmp_drawing.DrawingSpec(\n",
        "\t\tcolor=(0,255,255),\n",
        "\t\tthickness=1,\n",
        "\t\tcircle_radius=1\n",
        "\t)\n",
        "\t)\n",
        "\n",
        "\t# Drawing Right hand Land Marks\n",
        "\tmp_drawing.draw_landmarks(\n",
        "\timage,\n",
        "\tresults.right_hand_landmarks,\n",
        "\tmp_holistic.HAND_CONNECTIONS\n",
        "\t)\n",
        "\n",
        "\t# Drawing Left hand Land Marks\n",
        "\tmp_drawing.draw_landmarks(\n",
        "\timage,\n",
        "\tresults.left_hand_landmarks,\n",
        "\tmp_holistic.HAND_CONNECTIONS\n",
        "\t)\n",
        "\n",
        "\t# Calculating the FPS\n",
        "\tcurrentTime = time.time()\n",
        "\tfps = 1 / (currentTime-previousTime)\n",
        "\tpreviousTime = currentTime\n",
        "\n",
        "\t# Displaying FPS on the image\n",
        "\tcv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "\n",
        "\t# Display the resulting image\n",
        "\tcv2.imshow(\"Facial and Hand Landmarks\", image)\n",
        "\n",
        "\t# Enter key 'q' to break the loop\n",
        "\tif cv2.waitKey(5) & 0xFF == ord('q'):\n",
        "\t\tbreak\n",
        "\n",
        "# When all the process is done\n",
        "# Release the capture and destroy all windows\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Code to access landmarks\n",
        "for landmark in mp_holistic.HandLandmark:\n",
        "\tprint(landmark, landmark.value)\n",
        "\n",
        "print(mp_holistic.HandLandmark.WRIST.value)\n"
      ],
      "metadata": {
        "id": "uy53KbjWR-E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOZhOUg-p4n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5df26e-3a29-478a-ce26-7b867fd89ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "#import os\n",
        "\n",
        "def read_file(sn,tn):\n",
        "\ts = cv2.imread('cube'+sn+'.jpeg')\n",
        "\ts = cv2.cvtColor(s,cv2.COLOR_BGR2LAB)\n",
        "\tt = cv2.imread('cube'+tn+'.jpeg')\n",
        "\tt = cv2.cvtColor(t,cv2.COLOR_BGR2LAB)\n",
        "\treturn s, t\n",
        "\n",
        "def get_mean_and_std(x):\n",
        "\tx_mean, x_std = cv2.meanStdDev(x)\n",
        "\tx_mean = np.hstack(np.around(x_mean,2))\n",
        "\tx_std = np.hstack(np.around(x_std,2))\n",
        "\treturn x_mean, x_std\n",
        "\n",
        "def color_transfer():\n",
        "\tsources = ['2']\n",
        "\ttargets = ['1']\n",
        "\n",
        "\tfor n in range(len(sources)):\n",
        "\t\tprint(\"Converting picture\"+str(n+1)+\"...\")\n",
        "\t\ts, t = read_file(sources[n],targets[n])\n",
        "\t\ts_mean, s_std = get_mean_and_std(s)\n",
        "\t\tt_mean, t_std = get_mean_and_std(t)\n",
        "\n",
        "\t\theight, width, channel = s.shape\n",
        "\t\tfor i in range(0,height):\n",
        "\t\t\tfor j in range(0,width):\n",
        "\t\t\t\tfor k in range(0,channel):\n",
        "\t\t\t\t\tx = s[i,j,k]\n",
        "\t\t\t\t\tx = ((x-s_mean[k])*(t_std[k]/s_std[k]))+t_mean[k]\n",
        "\t\t\t\t\t# round or +0.5\n",
        "\t\t\t\t\tx = round(x)\n",
        "\t\t\t\t\t# boundary check\n",
        "\t\t\t\t\tx = 0 if x<0 else x\n",
        "\t\t\t\t\tx = 255 if x>255 else x\n",
        "\t\t\t\t\ts[i,j,k] = x\n",
        "\n",
        "\t\ts = cv2.cvtColor(s,cv2.COLOR_LAB2BGR)\n",
        "\t\tcv2.imwrite('r'+str(n+1)+'.jpg',s)\n",
        "\n",
        "color_transfer()"
      ],
      "metadata": {
        "id": "d5xond617Mlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262bd6da-33c0-4a36-ad92-25eb311bda39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting picture1...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqjcCdKqOUha6OoP0TsvK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}